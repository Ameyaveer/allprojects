# -*- coding: utf-8 -*-
"""Image Classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YtO1T6QB3UvO63HTM80T-_oWWR3Hx9lb
"""

from google.colab import drive
drive.mount('/content/drive')

"""Loading Libraries"""

import matplotlib.pyplot as plt
import numpy as np
import os
import tensorflow as tf
import random
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten, Dropout, BatchNormalization
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from PIL import Image
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import classification_report
from keras.callbacks import EarlyStopping

"""

Labeling, Agumenting Images, Train, Test split"""

# Define the path to the main folder containing subfolders with images
main_folder = "/content/drive/MyDrive/Object_Images"

# Define label mapping
label_mapping = { "Car": 0, "Flower": 1, "Shoes": 2, "Sports_Ball" : 3, "Water_Bottle": 4}

# Define the ImageDataGenerator for data augmentation (on-the-fly) and preprocessing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    rotation_range=30,  # Rotate images randomly up to 30 degrees
    width_shift_range=0.1,  # Shift images horizontally up to 10% of the widthq
    height_shift_range=0.1,  # Shift images vertically up to 10% of the height
    brightness_range=[0.8, 1.2],  # Adjust brightness randomly
    validation_split=0.3 #train and test split
)

test_datagen = ImageDataGenerator(rescale=1./255)

# Create training and validation data generators
train_generator = train_datagen.flow_from_directory(
    main_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training')

validation_generator = train_datagen.flow_from_directory(
    main_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation')

# Get the class indices from the generators
train_class_indices = train_generator.class_indices
validation_class_indices = validation_generator.class_indices

# Invert the dictionary to map indices to class names
train_inverse_indices = {v: k for k, v in train_class_indices.items()}
validation_inverse_indices = {v: k for k, v in validation_class_indices.items()}

# Count the number of images in each class in training set
print("Number of images in each class:")
for class_index in sorted(train_class_indices.values()):
    class_name = train_inverse_indices[class_index]
    class_dir = os.path.join(main_folder, class_name)
    num_images = len(os.listdir(class_dir))
    print(f"{class_name}: {num_images} images")

"""Plotting 16 random images"""

import matplotlib.pyplot as plt
import numpy as np
from random import sample
from PIL import Image

# Get a list of filenames and labels from the training generator
filenames = train_generator.filenames
labels = train_generator.classes

# Select 16 random indices
random_indices = sample(range(len(filenames)), 16)

# Create a figure with 4x4 subplots
fig, axs = plt.subplots(4, 4, figsize=(12, 12))
axs = axs.ravel()

# Load, resize, and plot the images with their labels
for i, idx in enumerate(random_indices):
    # Construct the full file path
    full_path = os.path.join(main_folder, filenames[idx])

    # Load the image
    img = Image.open(full_path)

    # Resize the image to a fixed size (e.g., 224x224)
    img = img.resize((224, 224))

    # Convert the image to a numpy array
    img = np.array(img)

    # Get the label
    label = list(label_mapping.keys())[list(label_mapping.values()).index(labels[idx])]

    # Plot the image and label
    axs[i].imshow(img)
    axs[i].set_title(label)
    axs[i].axis('off')

# Adjust the spacing between subplots
plt.subplots_adjust(wspace=0.1, hspace=0.1)
plt.show()

"""### VGG 16 Architecture"""

# Load the pre-trained VGG16 model
vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model layers
for layer in vgg16_model.layers:
    layer.trainable = False

SEED = 44
tf.random.set_seed(SEED)

'''
#Iteration 1
# Define the model architecture
model = Sequential([
    vgg16_model,
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(len(label_mapping), activation='softmax')
])

#Iteration 2
model = Sequential([
    vgg16_model,
    GlobalAveragePooling2D(),
    Dense(512, activation='relu'),
    BatchNormalization(),  # Add batch normalization layer
    Dropout(0.7),
    Dense(len(label_mapping), activation='softmax')
])

#Iteration 3
# Define the model architecture with L2 regularization and increased dropout
model = Sequential([
    vgg16_model,
    GlobalAveragePooling2D(),
    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),  # Add L2 regularization
    BatchNormalization(),
    Dropout(0.7),  # Increase dropout rate
    Dense(len(label_mapping), activation='softmax')
])

#Iteration 4
model = Sequential([
    vgg16_model,
    GlobalAveragePooling2D(),
    Dense(1024, activation='relu'),  # Increased the number of units in the first dense layer
    BatchNormalization(),
    Dropout(0.5),  # Decreased the dropout rate
    Dense(512, activation='relu'),  # Added an additional dense layer
    BatchNormalization(),
    Dropout(0.5),
    Dense(len(label_mapping), activation='softmax')
])

])
#Iteration 5
model = Sequential([
    vgg16_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),
    Dense(1024, activation='relu', kernel_regularizer=l2(0.001)),
    BatchNormalization(),
    Dropout(0.5),
    Dense(len(label_mapping), activation='softmax')
])
'''
#Iteration 6 - best model
model = Sequential([
    vgg16_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),
    Dense(2048, activation='relu', kernel_regularizer=l2(0.001)), # increased units from 1024 to 2048
    BatchNormalization(),
    Dropout(0.5),
    Dense(len(label_mapping), activation='softmax')
])
'''
#Iteration 7
model = Sequential([
    vgg16_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),
    Dense(2048, activation='relu', kernel_regularizer=l2(0.005)), # increased kernel_regularizer from 0.001 to 0.005
    BatchNormalization(),
    Dropout(0.5),
    Dense(len(label_mapping), activation='softmax')
])

#Iteration 8
model = Sequential([
    vgg16_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),
    Dense(4048, activation='relu', kernel_regularizer=l2(0.005)), # increased kernel_regularizer from 0.001 to 0.005
    BatchNormalization(),
    Dropout(0.5),
    Dense(len(label_mapping), activation='softmax')
])

#Iteration 9
model = Sequential([
    vgg16_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),
    Dense(1024, activation='relu', kernel_regularizer=l2(0.001)),
    BatchNormalization(),
    Dropout(0.5),
    Dense(1024, activation='relu', kernel_regularizer=l2(0.001)),
    BatchNormalization(),
    Dropout(0.5),
    Dense(len(label_mapping), activation='softmax')
])

'''

"""Training VGG 16"""

# Define an early stopping callback
early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)

model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])
epochs = 15
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // 32,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // 32,
    epochs=epochs,
    verbose=1, # Set verbose=1 to print progress during training
    callbacks=[early_stopping]  # Add the early stopping callback
)

# Print training and validation accuracies after each epoch
for epoch in range(epochs):
    train_acc = history.history['accuracy'][epoch]
    val_acc = history.history['val_accuracy'][epoch]
    print(f'Epoch {epoch+1}/{epochs}: Training accuracy = {train_acc:.4f}, Validation accuracy = {val_acc:.4f}')

# Print the final training and validation accuracies
print(f'\nFinal training accuracy: {history.history["accuracy"][-1]:.4f}')
print(f'Final validation accuracy: {history.history["val_accuracy"][-1]:.4f}')

"""Confusion Matrix"""

# Get the true labels for the validation dataset
true_labels = validation_generator.classes

# Make predictions for the validation dataset
predictions = model.predict(validation_generator)

# Decode predictions to get predicted labels
predicted_labels = np.argmax(predictions, axis=1)

# Generate confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)

# Print confusion matrix
print("Confusion Matrix:")
print(cm)

# Generate classification report
report = classification_report(true_labels, predicted_labels, target_names=label_mapping.keys())

# Print classification report
print("Classification Report:")
print(report)

# Plot confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='BuPu', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""Save model using joblib"""

import joblib
# Save the model
joblib.dump(model, 'Image_Object_Classifier.joblib')

"""Load model"""

loaded_model = joblib.load('Image_Object_Classifier.joblib')

"""Input Image"""

# Load and preprocess the input image
input_image_path = "/content/water bottle.png"
img = image.load_img(input_image_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
preprocessed_img = img_array / 255.0  # Rescale to [0,1]

# Make predictions
predictions = model.predict(preprocessed_img)

# Decode predictions
predicted_class = np.argmax(predictions)
predicted_label = list(label_mapping.keys())[predicted_class]
confidence = predictions[0][predicted_class]

# Print predicted class and confidence
print("Predicted Class:", predicted_label)
print("Confidence:", confidence)

# Display the input image
plt.imshow(img)
plt.axis('off')
plt.title(f'Predicted Class: {predicted_label}')
plt.show()

"""### ResNet 50 Architecture"""

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Load the pre-trained ResNet50 model
resnet50_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the base model layers
for layer in resnet50_model.layers:
    layer.trainable = False

SEED = 42
tf.random.set_seed(SEED)

# Define the ImageDataGenerator for data augmentation and preprocessing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1,
    brightness_range=[0.8, 1.2],
    validation_split=0.2
)

test_datagen = ImageDataGenerator(rescale=1./255)

# Create training and validation data generators
train_generator = train_datagen.flow_from_directory(
    main_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    main_folder,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

'''
# Define the model architecture
#Iteration 1
model_2 = tf.keras.Sequential([
    resnet50_model,
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(len(label_mapping), activation='softmax')
])

'''
#Iteration 2
model_2 = tf.keras.Sequential([
    resnet50_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(len(label_mapping), activation='softmax')
])
'''

"""Training ResNet 50"""

# Compile the model
model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
epochs = 10
history_ = model_2.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // 32,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // 32,
    verbose=1)  # Set verbose=1 to print progress during training

# Print training and validation accuracies after each epoch
for epoch in range(epochs):
    train_acc = history_.history['accuracy'][epoch]
    val_acc = history_.history['val_accuracy'][epoch]
    print(f'Epoch {epoch+1}/{epochs}: Training accuracy = {train_acc:.4f}, Validation accuracy = {val_acc:.4f}')

# Print the final training and validation accuracies
print(f'\nFinal training accuracy: {history_.history["accuracy"][-1]:.4f}')
print(f'Final validation accuracy: {history_.history["val_accuracy"][-1]:.4f}')

"""Confusion Matrix"""

# Get the true labels for the validation dataset
true_labels = validation_generator.classes

# Make predictions for the validation dataset
predictions = model_2.predict(validation_generator)

# Decode predictions to get predicted labels
predicted_labels = np.argmax(predictions, axis=1)

# Generate confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)

# Print confusion matrix
print("Confusion Matrix:")
print(cm)

# Generate classification report
report = classification_report(true_labels, predicted_labels, target_names=label_mapping.keys())

# Print classification report
print("Classification Report:")
print(report)

# Plot confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""Input Image"""

# Load and preprocess the input image
input_image_path = "/content/shoe.png"
img = image.load_img(input_image_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
preprocessed_img = img_array / 255.0  # Rescale to [0,1]

# Make predictions
predictions = model_2.predict(preprocessed_img)

# Decode predictions
predicted_class = np.argmax(predictions)
predicted_label = list(label_mapping.keys())[predicted_class]
confidence = predictions[0][predicted_class]

# Print predicted class and confidence
print("Predicted Class:", predicted_label)
print("Confidence:", confidence)

# Display the input image
plt.imshow(img)
plt.axis('off')
plt.title(f'Predicted Class: {predicted_label}')
plt.show()